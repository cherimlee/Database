{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Yz5CJRhZwJXb"
   },
   "outputs": [],
   "source": [
    "import urllib3\n",
    "import zipfile\n",
    "import shutil\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1inVOFJzwI8j"
   },
   "outputs": [],
   "source": [
    "http = urllib3.PoolManager()\n",
    "url ='http://www.manythings.org/anki/fra-eng.zip'\n",
    "filename = 'fra-eng.zip'\n",
    "path = os.getcwd()\n",
    "zipfilename = os.path.join(path, filename)\n",
    "with http.request('GET', url, preload_content=False) as r, open(zipfilename, 'wb') as out_file:       \n",
    "    shutil.copyfileobj(r, out_file)\n",
    "\n",
    "with zipfile.ZipFile(zipfilename, 'r') as zip_ref:\n",
    "    zip_ref.extractall(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "seyA5LGZv_uF",
    "outputId": "10397183-5f94-4cd0-c0e7-da785202dc56"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "177210"
      ]
     },
     "execution_count": 36,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "lines= pd.read_csv('fra.txt', names=['src', 'tar', 'CC'], sep='\\t')\n",
    "len(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 347
    },
    "id": "hvXdi_d6wg8U",
    "outputId": "9e65e521-215a-4048-8f48-4c6fa3e9b693"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>src</th>\n",
       "      <th>tar</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29632</th>\n",
       "      <td>I heard the message.</td>\n",
       "      <td>J'entendis le message.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59927</th>\n",
       "      <td>Are you out of your mind?</td>\n",
       "      <td>Êtes-vous fou ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36122</th>\n",
       "      <td>I was really unlucky.</td>\n",
       "      <td>J'étais très malchanceux.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24920</th>\n",
       "      <td>I'm laying you off.</td>\n",
       "      <td>Je te licencie.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40808</th>\n",
       "      <td>Have yourself a drink.</td>\n",
       "      <td>Servez-vous un verre !</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33446</th>\n",
       "      <td>You're kind of cute.</td>\n",
       "      <td>Vous êtes mignons, dans votre genre.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49715</th>\n",
       "      <td>It'll be too late then.</td>\n",
       "      <td>Ce sera alors trop tard.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52234</th>\n",
       "      <td>Where are your parents?</td>\n",
       "      <td>Où sont tes parents ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2138</th>\n",
       "      <td>I am better.</td>\n",
       "      <td>Je vais mieux.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42063</th>\n",
       "      <td>I like French cooking.</td>\n",
       "      <td>J'apprécie la cuisine française.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             src                                   tar\n",
       "29632       I heard the message.                J'entendis le message.\n",
       "59927  Are you out of your mind?                       Êtes-vous fou ?\n",
       "36122      I was really unlucky.             J'étais très malchanceux.\n",
       "24920        I'm laying you off.                       Je te licencie.\n",
       "40808     Have yourself a drink.                Servez-vous un verre !\n",
       "33446       You're kind of cute.  Vous êtes mignons, dans votre genre.\n",
       "49715    It'll be too late then.              Ce sera alors trop tard.\n",
       "52234    Where are your parents?                 Où sont tes parents ?\n",
       "2138                I am better.                        Je vais mieux.\n",
       "42063     I like French cooking.      J'apprécie la cuisine française."
      ]
     },
     "execution_count": 37,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines = lines.loc[:, 'src':'tar']\n",
    "lines = lines[0:60000] # 6만개만 저장\n",
    "lines.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 347
    },
    "id": "Zsi21Xu3wlGy",
    "outputId": "b91783a2-c786-4f15-f849-7b952565d933"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>src</th>\n",
       "      <th>tar</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>35048</th>\n",
       "      <td>I bet I can prove it.</td>\n",
       "      <td>\\t Je parie que je peux le prouver. \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494</th>\n",
       "      <td>Am I late?</td>\n",
       "      <td>\\t Suis-je en retard ? \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34079</th>\n",
       "      <td>Do you need anything?</td>\n",
       "      <td>\\t As-tu besoin de quoi que ce soit ? \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10447</th>\n",
       "      <td>Go to your room.</td>\n",
       "      <td>\\t Va dans ta chambre ! \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33064</th>\n",
       "      <td>Why are we laughing?</td>\n",
       "      <td>\\t Pourquoi est-ce qu'on rigole ? \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9551</th>\n",
       "      <td>We're not done.</td>\n",
       "      <td>\\t Nous n'en avons pas terminé. \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25037</th>\n",
       "      <td>I've found the key.</td>\n",
       "      <td>\\t J'ai trouvé la clé. \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31154</th>\n",
       "      <td>Not everyone agreed.</td>\n",
       "      <td>\\t Tout le monde n'était pas d'accord. \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16270</th>\n",
       "      <td>Tell Tom to wait.</td>\n",
       "      <td>\\t Dites à Tom d'attendre. \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47251</th>\n",
       "      <td>Have you been drinking?</td>\n",
       "      <td>\\t Avez-vous bu ? \\n</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           src                                        tar\n",
       "35048    I bet I can prove it.     \\t Je parie que je peux le prouver. \\n\n",
       "494                 Am I late?                  \\t Suis-je en retard ? \\n\n",
       "34079    Do you need anything?   \\t As-tu besoin de quoi que ce soit ? \\n\n",
       "10447         Go to your room.                 \\t Va dans ta chambre ! \\n\n",
       "33064     Why are we laughing?       \\t Pourquoi est-ce qu'on rigole ? \\n\n",
       "9551           We're not done.         \\t Nous n'en avons pas terminé. \\n\n",
       "25037      I've found the key.                  \\t J'ai trouvé la clé. \\n\n",
       "31154     Not everyone agreed.  \\t Tout le monde n'était pas d'accord. \\n\n",
       "16270        Tell Tom to wait.              \\t Dites à Tom d'attendre. \\n\n",
       "47251  Have you been drinking?                       \\t Avez-vous bu ? \\n"
      ]
     },
     "execution_count": 38,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines.tar = lines.tar.apply(lambda x : '\\t '+ x + ' \\n')\n",
    "lines.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jHrky952xM6T"
   },
   "outputs": [],
   "source": [
    "# 글자 집합 구축\n",
    "src_vocab=set()\n",
    "for line in lines.src: # 1줄씩 읽음\n",
    "    for char in line: # 1개의 글자씩 읽음\n",
    "        src_vocab.add(char)\n",
    "\n",
    "tar_vocab=set()\n",
    "for line in lines.tar:\n",
    "    for char in line:\n",
    "        tar_vocab.add(char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "id": "DBrUwEU0xORz",
    "outputId": "f725e489-d09f-467c-ee69-3c4de316884b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79\n",
      "105\n"
     ]
    }
   ],
   "source": [
    "src_vocab_size = len(src_vocab)+1\n",
    "tar_vocab_size = len(tar_vocab)+1\n",
    "print(src_vocab_size)\n",
    "print(tar_vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "id": "RjO5UE_VxP9b",
    "outputId": "4cf6fed9-f252-4d20-eca9-891e2736d2d8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['W', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n",
      "['U', 'V', 'W', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x']\n"
     ]
    }
   ],
   "source": [
    "src_vocab = sorted(list(src_vocab))\n",
    "tar_vocab = sorted(list(tar_vocab))\n",
    "print(src_vocab[45:75])\n",
    "print(tar_vocab[45:75])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "id": "-ZyVbd5KxRbE",
    "outputId": "a46c986c-1746-4155-8de6-3770ec96590c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{' ': 1, '!': 2, '\"': 3, '$': 4, '%': 5, '&': 6, \"'\": 7, ',': 8, '-': 9, '.': 10, '/': 11, '0': 12, '1': 13, '2': 14, '3': 15, '4': 16, '5': 17, '6': 18, '7': 19, '8': 20, '9': 21, ':': 22, '?': 23, 'A': 24, 'B': 25, 'C': 26, 'D': 27, 'E': 28, 'F': 29, 'G': 30, 'H': 31, 'I': 32, 'J': 33, 'K': 34, 'L': 35, 'M': 36, 'N': 37, 'O': 38, 'P': 39, 'Q': 40, 'R': 41, 'S': 42, 'T': 43, 'U': 44, 'V': 45, 'W': 46, 'X': 47, 'Y': 48, 'Z': 49, 'a': 50, 'b': 51, 'c': 52, 'd': 53, 'e': 54, 'f': 55, 'g': 56, 'h': 57, 'i': 58, 'j': 59, 'k': 60, 'l': 61, 'm': 62, 'n': 63, 'o': 64, 'p': 65, 'q': 66, 'r': 67, 's': 68, 't': 69, 'u': 70, 'v': 71, 'w': 72, 'x': 73, 'y': 74, 'z': 75, 'é': 76, '’': 77, '€': 78}\n",
      "{'\\t': 1, '\\n': 2, ' ': 3, '!': 4, '\"': 5, '%': 6, '&': 7, \"'\": 8, '(': 9, ')': 10, ',': 11, '-': 12, '.': 13, '0': 14, '1': 15, '2': 16, '3': 17, '4': 18, '5': 19, '6': 20, '7': 21, '8': 22, '9': 23, ':': 24, '?': 25, 'A': 26, 'B': 27, 'C': 28, 'D': 29, 'E': 30, 'F': 31, 'G': 32, 'H': 33, 'I': 34, 'J': 35, 'K': 36, 'L': 37, 'M': 38, 'N': 39, 'O': 40, 'P': 41, 'Q': 42, 'R': 43, 'S': 44, 'T': 45, 'U': 46, 'V': 47, 'W': 48, 'X': 49, 'Y': 50, 'Z': 51, 'a': 52, 'b': 53, 'c': 54, 'd': 55, 'e': 56, 'f': 57, 'g': 58, 'h': 59, 'i': 60, 'j': 61, 'k': 62, 'l': 63, 'm': 64, 'n': 65, 'o': 66, 'p': 67, 'q': 68, 'r': 69, 's': 70, 't': 71, 'u': 72, 'v': 73, 'w': 74, 'x': 75, 'y': 76, 'z': 77, '\\xa0': 78, '«': 79, '»': 80, 'À': 81, 'Ç': 82, 'É': 83, 'Ê': 84, 'Ô': 85, 'à': 86, 'â': 87, 'ç': 88, 'è': 89, 'é': 90, 'ê': 91, 'ë': 92, 'î': 93, 'ï': 94, 'ô': 95, 'ù': 96, 'û': 97, 'œ': 98, 'С': 99, '\\u2009': 100, '\\u200b': 101, '‘': 102, '’': 103, '\\u202f': 104}\n"
     ]
    }
   ],
   "source": [
    "src_to_index = dict([(word, i+1) for i, word in enumerate(src_vocab)])\n",
    "tar_to_index = dict([(word, i+1) for i, word in enumerate(tar_vocab)])\n",
    "print(src_to_index)\n",
    "print(tar_to_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2psnowDVYo5P"
   },
   "source": [
    "기본적인 전처리를 거친 후의 데이터입니다. 데이터는 기본적으로 세 종류가 있어야 합니다.  \n",
    "encoder_input은 인코더의 입력을 위한 데이터입니다.  \n",
    "decoder_input은 디코더의 입력을 위한 데이터입니다. 그렇기 때문에 시작을 의미하는 \\t 토큰이 필요합니다.  \n",
    "decoder_target은 디코더의 레이블을 위한 데이터입니다. 그렇기 때문에 종료를 의미하는 \\n 토큰이 필요합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "jLr50UH1xSLG",
    "outputId": "654d452d-2c29-4d8c-d662-b087ebaeee45"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[30, 64, 10], [31, 58, 10], [31, 58, 10], [41, 70, 63, 2], [41, 70, 63, 2]]\n"
     ]
    }
   ],
   "source": [
    "encoder_input = []\n",
    "for line in lines.src: #입력 데이터에서 1줄씩 문장을 읽음\n",
    "    temp_X = []\n",
    "    for w in line: #각 줄에서 1개씩 글자를 읽음\n",
    "      temp_X.append(src_to_index[w]) # 글자를 해당되는 정수로 변환\n",
    "    encoder_input.append(temp_X)\n",
    "print(encoder_input[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "_3DeJJ8IxTzK",
    "outputId": "d3117a29-d471-4f78-da04-3c82ff9433b0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 3, 47, 52, 3, 4, 3, 2], [1, 3, 44, 52, 63, 72, 71, 3, 4, 3, 2], [1, 3, 44, 52, 63, 72, 71, 13, 3, 2], [1, 3, 28, 66, 72, 69, 70, 104, 4, 3, 2], [1, 3, 28, 66, 72, 69, 56, 77, 104, 4, 3, 2]]\n"
     ]
    }
   ],
   "source": [
    "decoder_input = []\n",
    "for line in lines.tar:\n",
    "    temp_X = []\n",
    "    for w in line:\n",
    "      temp_X.append(tar_to_index[w])\n",
    "    decoder_input.append(temp_X)\n",
    "print(decoder_input[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "V68v4hj3xYLc",
    "outputId": "37cfc686-9f09-40ef-bdd0-b9456537a430"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3, 47, 52, 3, 4, 3, 2], [3, 44, 52, 63, 72, 71, 3, 4, 3, 2], [3, 44, 52, 63, 72, 71, 13, 3, 2], [3, 28, 66, 72, 69, 70, 104, 4, 3, 2], [3, 28, 66, 72, 69, 56, 77, 104, 4, 3, 2]]\n"
     ]
    }
   ],
   "source": [
    "decoder_target = []\n",
    "for line in lines.tar:\n",
    "    t=0\n",
    "    temp_X = []\n",
    "    for w in line:\n",
    "      if t>0:\n",
    "        temp_X.append(tar_to_index[w])\n",
    "      t=t+1\n",
    "    decoder_target.append(temp_X)\n",
    "print(decoder_target[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "id": "MxKqHu6GxZs1",
    "outputId": "221dee76-9e7b-4e17-d46f-23de6ba87eee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25\n",
      "76\n"
     ]
    }
   ],
   "source": [
    "max_src_len = max([len(line) for line in lines.src])\n",
    "max_tar_len = max([len(line) for line in lines.tar])\n",
    "print(max_src_len)\n",
    "print(max_tar_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BAiLC3W7xbTj"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "encoder_input = pad_sequences(encoder_input, maxlen=max_src_len, padding='post')\n",
    "decoder_input = pad_sequences(decoder_input, maxlen=max_tar_len, padding='post')\n",
    "decoder_target = pad_sequences(decoder_target, maxlen=max_tar_len, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nWKdRFOtxcyU"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "encoder_input = to_categorical(encoder_input)\n",
    "decoder_input = to_categorical(decoder_input)\n",
    "decoder_target = to_categorical(decoder_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EYgMNHUWZBEg"
   },
   "source": [
    "인코더와 디코더 모델을 설계해봅시다.  \n",
    "\n",
    "인코더 모델은 LSTM을 사용합니다. return_state=True이므로  \n",
    "마지막 시점의 은닉 상태인 state_h와 state_c를 리턴합니다.  \n",
    "\n",
    "현재 return_sequences는 값을 지정해주지 않았는데, 디폴트값이 False이므로  \n",
    "이 경우 encoder_outputs은 마지막 시점의 은닉상태입니다.  \n",
    "\n",
    "state_h와 state_c를 encoder_state에 저장해둡니다. 이를 컨텍스트 벡터로 사용하기 위함입니다.  \n",
    "\n",
    "참고 : https://wikidocs.net/106473"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Cv1RK5MTxeFC"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "encoder_inputs = Input(shape=(None, src_vocab_size))\n",
    "encoder_lstm = LSTM(units=256, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder_lstm(encoder_inputs)\n",
    "# encoder_outputs도 같이 리턴받기는 했지만 여기서는 필요없으므로 이 값은 버림.\n",
    "encoder_states = [state_h, state_c]\n",
    "# LSTM은 바닐라 RNN과는 달리 상태가 두 개. 바로 은닉 상태와 셀 상태."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t-LB2nsWZoq-"
   },
   "source": [
    "디코더 모델 또한 LSTM을 사용합니다. 인코더와는 달리 return_sequences가 True인데,  \n",
    "이러면 모든 시점의 은닉 상태를 리턴합니다. 이는 decoder_outputs에 저장되었습니다.  \n",
    "이를 출력층으로 통과시켜서 예측합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m_KtCjeFx9tW"
   },
   "outputs": [],
   "source": [
    "decoder_inputs = Input(shape=(None, tar_vocab_size))\n",
    "decoder_lstm = LSTM(units=256, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _= decoder_lstm(decoder_inputs, initial_state=encoder_states)\n",
    "# 디코더의 첫 상태를 인코더의 은닉 상태, 셀 상태로 합니다.\n",
    "decoder_softmax_layer = Dense(tar_vocab_size, activation='softmax')\n",
    "decoder_outputs = decoder_softmax_layer(decoder_outputs)\n",
    "\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "model.compile(optimizer=\"rmsprop\", loss=\"categorical_crossentropy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "I6UYSlgRx_z0",
    "outputId": "9f8c92c4-9bfb-4793-bc42-a8d254505855"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "750/750 [==============================] - 13s 17ms/step - loss: 0.7774 - val_loss: 0.6827\n",
      "Epoch 2/50\n",
      "750/750 [==============================] - 12s 15ms/step - loss: 0.4753 - val_loss: 0.5522\n",
      "Epoch 3/50\n",
      "750/750 [==============================] - 12s 15ms/step - loss: 0.3965 - val_loss: 0.4856\n",
      "Epoch 4/50\n",
      "750/750 [==============================] - 12s 15ms/step - loss: 0.3530 - val_loss: 0.4454\n",
      "Epoch 5/50\n",
      "750/750 [==============================] - 12s 16ms/step - loss: 0.3241 - val_loss: 0.4198\n",
      "Epoch 6/50\n",
      "750/750 [==============================] - 12s 15ms/step - loss: 0.3024 - val_loss: 0.4048\n",
      "Epoch 7/50\n",
      "750/750 [==============================] - 12s 16ms/step - loss: 0.2857 - val_loss: 0.3944\n",
      "Epoch 8/50\n",
      "750/750 [==============================] - 12s 15ms/step - loss: 0.2723 - val_loss: 0.3816\n",
      "Epoch 9/50\n",
      "750/750 [==============================] - 12s 15ms/step - loss: 0.2612 - val_loss: 0.3740\n",
      "Epoch 10/50\n",
      "750/750 [==============================] - 12s 15ms/step - loss: 0.2515 - val_loss: 0.3703\n",
      "Epoch 11/50\n",
      "750/750 [==============================] - 12s 16ms/step - loss: 0.2432 - val_loss: 0.3646\n",
      "Epoch 12/50\n",
      "750/750 [==============================] - 12s 16ms/step - loss: 0.2357 - val_loss: 0.3613\n",
      "Epoch 13/50\n",
      "750/750 [==============================] - 12s 15ms/step - loss: 0.2290 - val_loss: 0.3587\n",
      "Epoch 14/50\n",
      "750/750 [==============================] - 12s 15ms/step - loss: 0.2227 - val_loss: 0.3585\n",
      "Epoch 15/50\n",
      "750/750 [==============================] - 12s 16ms/step - loss: 0.2171 - val_loss: 0.3574\n",
      "Epoch 16/50\n",
      "750/750 [==============================] - 12s 16ms/step - loss: 0.2118 - val_loss: 0.3569\n",
      "Epoch 17/50\n",
      "750/750 [==============================] - 12s 15ms/step - loss: 0.2069 - val_loss: 0.3563\n",
      "Epoch 18/50\n",
      "750/750 [==============================] - 12s 16ms/step - loss: 0.2024 - val_loss: 0.3573\n",
      "Epoch 19/50\n",
      "750/750 [==============================] - 12s 16ms/step - loss: 0.1980 - val_loss: 0.3582\n",
      "Epoch 20/50\n",
      "750/750 [==============================] - 12s 16ms/step - loss: 0.1939 - val_loss: 0.3588\n",
      "Epoch 21/50\n",
      "750/750 [==============================] - 12s 15ms/step - loss: 0.1901 - val_loss: 0.3600\n",
      "Epoch 22/50\n",
      "750/750 [==============================] - 12s 15ms/step - loss: 0.1865 - val_loss: 0.3617\n",
      "Epoch 23/50\n",
      "750/750 [==============================] - 12s 16ms/step - loss: 0.1832 - val_loss: 0.3629\n",
      "Epoch 24/50\n",
      "750/750 [==============================] - 12s 16ms/step - loss: 0.1798 - val_loss: 0.3651\n",
      "Epoch 25/50\n",
      "750/750 [==============================] - 12s 15ms/step - loss: 0.1768 - val_loss: 0.3645\n",
      "Epoch 26/50\n",
      "750/750 [==============================] - 12s 15ms/step - loss: 0.1738 - val_loss: 0.3673\n",
      "Epoch 27/50\n",
      "750/750 [==============================] - 12s 16ms/step - loss: 0.1709 - val_loss: 0.3680\n",
      "Epoch 28/50\n",
      "750/750 [==============================] - 12s 16ms/step - loss: 0.1682 - val_loss: 0.3720\n",
      "Epoch 29/50\n",
      "750/750 [==============================] - 12s 16ms/step - loss: 0.1657 - val_loss: 0.3752\n",
      "Epoch 30/50\n",
      "750/750 [==============================] - 12s 15ms/step - loss: 0.1632 - val_loss: 0.3809\n",
      "Epoch 31/50\n",
      "750/750 [==============================] - 12s 16ms/step - loss: 0.1607 - val_loss: 0.3807\n",
      "Epoch 32/50\n",
      "750/750 [==============================] - 12s 16ms/step - loss: 0.1586 - val_loss: 0.3820\n",
      "Epoch 33/50\n",
      "750/750 [==============================] - 12s 15ms/step - loss: 0.1563 - val_loss: 0.3852\n",
      "Epoch 34/50\n",
      "750/750 [==============================] - 12s 15ms/step - loss: 0.1543 - val_loss: 0.3857\n",
      "Epoch 35/50\n",
      "750/750 [==============================] - 12s 16ms/step - loss: 0.1521 - val_loss: 0.3883\n",
      "Epoch 36/50\n",
      "750/750 [==============================] - 12s 16ms/step - loss: 0.1502 - val_loss: 0.3899\n",
      "Epoch 37/50\n",
      "750/750 [==============================] - 12s 15ms/step - loss: 0.1482 - val_loss: 0.3937\n",
      "Epoch 38/50\n",
      "750/750 [==============================] - 12s 15ms/step - loss: 0.1466 - val_loss: 0.3973\n",
      "Epoch 39/50\n",
      "750/750 [==============================] - 12s 16ms/step - loss: 0.1447 - val_loss: 0.3993\n",
      "Epoch 40/50\n",
      "750/750 [==============================] - 12s 16ms/step - loss: 0.1431 - val_loss: 0.4015\n",
      "Epoch 41/50\n",
      "750/750 [==============================] - 12s 16ms/step - loss: 0.1416 - val_loss: 0.4031\n",
      "Epoch 42/50\n",
      "750/750 [==============================] - 12s 15ms/step - loss: 0.1397 - val_loss: 0.4071\n",
      "Epoch 43/50\n",
      "750/750 [==============================] - 12s 16ms/step - loss: 0.1383 - val_loss: 0.4103\n",
      "Epoch 44/50\n",
      "750/750 [==============================] - 12s 15ms/step - loss: 0.1368 - val_loss: 0.4129\n",
      "Epoch 45/50\n",
      "750/750 [==============================] - 12s 15ms/step - loss: 0.1354 - val_loss: 0.4164\n",
      "Epoch 46/50\n",
      "750/750 [==============================] - 12s 16ms/step - loss: 0.1340 - val_loss: 0.4164\n",
      "Epoch 47/50\n",
      "750/750 [==============================] - 12s 16ms/step - loss: 0.1327 - val_loss: 0.4217\n",
      "Epoch 48/50\n",
      "750/750 [==============================] - 12s 16ms/step - loss: 0.1313 - val_loss: 0.4236\n",
      "Epoch 49/50\n",
      "750/750 [==============================] - 12s 15ms/step - loss: 0.1300 - val_loss: 0.4253\n",
      "Epoch 50/50\n",
      "750/750 [==============================] - 12s 16ms/step - loss: 0.1289 - val_loss: 0.4282\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fa06716a0b8>"
      ]
     },
     "execution_count": 51,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=[encoder_input, decoder_input], y=decoder_target, batch_size=64, epochs=50, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zp_AxqGbZ3at"
   },
   "source": [
    "학습을 다했다면 이를 테스트 과정에 사용할 차례입니다.  \n",
    "\n",
    "인코더는 달라진 것이 없으므로 앞서 사용한 인코더를 그대로 사용합니다.  \n",
    "하지만 디코더는 학습 단계(티처 포싱 사용)과 테스트 단계(이전 시점의 예측을 현재 시점의 입력으로 사용)의 동작 방식이 다르므로  \n",
    "\n",
    "디코더의 구조를 변경해줄 필요가 있습니다.  \n",
    "\n",
    "학습 과정과는 달리 state_h와 state_c를 버리지 않고있음을 주목합시다.  \n",
    "테스트 단계에서의 디코더의 동작 자체는 decoder_sequence()라는 함수에서 컨트롤합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "E9EhO43ayAz6"
   },
   "outputs": [],
   "source": [
    "encoder_model = Model(inputs=encoder_inputs, outputs=encoder_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cR_4bThIyCRk"
   },
   "outputs": [],
   "source": [
    "# 이전 시점의 상태들을 저장하는 텐서\n",
    "decoder_state_input_h = Input(shape=(256,))\n",
    "decoder_state_input_c = Input(shape=(256,))\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "decoder_outputs, state_h, state_c = decoder_lstm(decoder_inputs, initial_state=decoder_states_inputs)\n",
    "# 문장의 다음 단어를 예측하기 위해서 초기 상태(initial_state)를 이전 시점의 상태로 사용. 이는 뒤의 함수 decode_sequence()에 구현\n",
    "decoder_states = [state_h, state_c]\n",
    "# 훈련 과정에서와 달리 LSTM의 리턴하는 은닉 상태와 셀 상태인 state_h와 state_c를 버리지 않음.\n",
    "decoder_outputs = decoder_softmax_layer(decoder_outputs)\n",
    "decoder_model = Model(inputs=[decoder_inputs] + decoder_states_inputs, outputs=[decoder_outputs] + decoder_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oy6gLQIAyDuz"
   },
   "outputs": [],
   "source": [
    "index_to_src = dict((i, char) for char, i in src_to_index.items())\n",
    "index_to_tar = dict((i, char) for char, i in tar_to_index.items())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eNtoNyknab1z"
   },
   "source": [
    "decode_sequence는 번역을 원하는 문장을 입력받으면  \n",
    "번역 문장을 출력하는 테스트 단계를 위한 함수입니다.  \n",
    "\n",
    "While문은 디코더의 각 시점을 컨트롤하는데 사용합니다.  \n",
    "각 루프가 디코더의 현재 시점이 됩니다.  \n",
    "\n",
    "최종적으로 리턴할 decoded_sentence라는 문자열에  \n",
    "지속적으로 현재 시점에 예측한 단어를 추가해나갑니다.  \n",
    "ex) I -> I like -> I like apples  \n",
    "\n",
    "target_seq는 이전 시점의 예측 결과이면서 현재 시점의 입력인 단어에 해당되는 원-핫 벡터입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KMnOKzgYyFsn"
   },
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "    # 입력으로부터 인코더의 상태를 얻음\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "\n",
    "    # <SOS>에 해당하는 원-핫 벡터 생성\n",
    "    target_seq = np.zeros((1, 1, tar_vocab_size))\n",
    "    target_seq[0, 0, tar_to_index['\\t']] = 1.\n",
    "\n",
    "    stop_condition = False\n",
    "    decoded_sentence = \"\"\n",
    "\n",
    "    # stop_condition이 True가 될 때까지 루프 반복\n",
    "    while not stop_condition:\n",
    "        # 이점 시점의 상태 states_value를 현 시점의 초기 상태로 사용\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
    "\n",
    "        # 예측 결과를 문자로 변환\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_char = index_to_tar[sampled_token_index]\n",
    "\n",
    "        # 현재 시점의 예측 문자를 예측 문장에 추가\n",
    "        decoded_sentence += sampled_char\n",
    "\n",
    "        # <eos>에 도달하거나 최대 길이를 넘으면 중단.\n",
    "        if (sampled_char == '\\n' or\n",
    "           len(decoded_sentence) > max_tar_len):\n",
    "            stop_condition = True\n",
    "\n",
    "        # 현재 시점의 예측 결과를 다음 시점의 입력으로 사용하기 위해 저장\n",
    "        target_seq = np.zeros((1, 1, tar_vocab_size))\n",
    "        target_seq[0, 0, sampled_token_index] = 1.\n",
    "\n",
    "        # 현재 시점의 상태를 다음 시점의 상태로 사용하기 위해 저장\n",
    "        states_value = [h, c]\n",
    "\n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ow-eKfrFzoIK"
   },
   "outputs": [],
   "source": [
    "from nltk.translate.bleu_score import corpus_bleu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 372
    },
    "id": "7ob9YTTgyGRg",
    "outputId": "c6ba0f85-7929-4688-a8c5-3452cd753767"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------\n",
      "입력 문장: Run!\n",
      "정답 문장:  Cours ! \n",
      "번역기가 번역한 문장:  Soit bien ! \n",
      "-----------------------------------\n",
      "입력 문장: I lied.\n",
      "정답 문장:  J'ai menti. \n",
      "번역기가 번역한 문장:  J'ai apprécié. \n",
      "-----------------------------------\n",
      "입력 문장: Come in.\n",
      "정답 문장:  Entre. \n",
      "번역기가 번역한 문장:  Entrez ! \n",
      "-----------------------------------\n",
      "입력 문장: Hurry up.\n",
      "정답 문장:  Magnez-vous ! \n",
      "번역기가 번역한 문장:  Magnez-vous ! \n",
      "-----------------------------------\n",
      "입력 문장: We walked.\n",
      "정답 문장:  Nous sommes allées à pied. \n",
      "번역기가 번역한 문장:  Nous l'avons tout. \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "for seq_index in [3,50,100,300,1001]: # 입력 문장의 인덱스\n",
    "    input_seq = encoder_input[seq_index: seq_index + 1]\n",
    "    decoded_sentence = decode_sequence(input_seq)\n",
    "    print(35 * \"-\")\n",
    "    print('입력 문장:', lines.src[seq_index])\n",
    "    print('정답 문장:', lines.tar[seq_index][1:len(lines.tar[seq_index])-1]) # '\\t'와 '\\n'을 빼고 출력\n",
    "    print('번역기가 번역한 문장:', decoded_sentence[:len(decoded_sentence)-1]) # '\\n'을 빼고 출력"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "machine_shape": "hm",
   "name": "Learning Spoons 6강 (seq2seq).ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
